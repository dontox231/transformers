{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30407,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/CjangCjengh/vits.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T02:49:59.395867Z","iopub.execute_input":"2023-12-01T02:49:59.396369Z","iopub.status.idle":"2023-12-01T02:50:19.748451Z","shell.execute_reply.started":"2023-12-01T02:49:59.396327Z","shell.execute_reply":"2023-12-01T02:50:19.746445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install Cython==0.29.21 librosa==0.8.0 unidecode==1.3.4 jamo==0.4.1 pypinyin==0.44.0 jieba==0.42.1\n!pip install cn2an==0.5.17 inflect==6.0.0 eng_to_ipa==0.0.2 ko_pron==1.3 indic_transliteration==2.3.37 num_thai==0.0.5 opencc==1.1.1\n\n!pip uninstall cmake -y\n!pip install pyopenjtalk==0.2.0\n!pip install cmake\n\n!pip install transformers==4.27.4\n!pip install icetk cpm_kernels gradio\n!pip install accelerate==0.17.1\n!pip install protobuf==3.20.0\n","metadata":{"execution":{"iopub.status.busy":"2023-04-02T10:30:30.468392Z","iopub.execute_input":"2023-04-02T10:30:30.468785Z","iopub.status.idle":"2023-04-02T10:34:11.285384Z","shell.execute_reply.started":"2023-04-02T10:30:30.46874Z","shell.execute_reply":"2023-04-02T10:34:11.283888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport transformers\nprint(torch.version.cuda,transformers.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T10:34:11.287493Z","iopub.execute_input":"2023-04-02T10:34:11.287829Z","iopub.status.idle":"2023-04-02T10:34:14.883967Z","shell.execute_reply.started":"2023-04-02T10:34:11.287776Z","shell.execute_reply":"2023-04-02T10:34:14.882661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working/vits')\n%cd monotonic_align\n!python setup.py build_ext --inplace\nos.chdir('/kaggle/working/vits')\nfrom os.path import join, exists\nimport torch.nn.functional as F\nimport commons\nimport utils\nfrom models import SynthesizerTrn\nos.chdir('/kaggle/working/vits/text')\nfrom japanese import japanese_to_romaji_with_accent, japanese_to_ipa, japanese_to_ipa2, japanese_to_ipa3\nfrom symbols import symbols\n\nfrom scipy.io.wavfile import write\nimport re\nos.chdir('/kaggle/working')\n\n# japanese_cleaners\n_pad        = '_'\n_punctuation = ',.!?-'\n_letters = 'AEINOQUabdefghijkmnoprstuvwyzʃʧ↓↑ '\n# Export all symbols:\nsymbols = [_pad] + list(_punctuation) + list(_letters)\n# Special symbol ids\nSPACE_ID = symbols.index(\" \")\n_symbol_to_id = {s: i for i, s in enumerate(symbols)}\n_id_to_symbol = {i: s for i, s in enumerate(symbols)}\n\ndef text_to_sequence(text):\n    sequence = []\n    clean_text = japanese_cleaners(text)\n    for symbol in clean_text:\n        if symbol not in _symbol_to_id.keys():\n            continue\n        symbol_id = _symbol_to_id[symbol]\n        sequence += [symbol_id]\n    return sequence\n\ndef japanese_cleaners(text):\n    text = japanese_to_romaji_with_accent(text)\n    text = re.sub(r'([A-Za-z])$', r'\\1.', text)\n    return text\ndef japanese_cleaners2(text):\n    return japanese_cleaners(text).replace('ts', 'ʦ').replace('...', '…')\n\ndef get_text(text, hps):\n    text_norm = text_to_sequence(text)\n    if hps.data.add_blank:\n        text_norm = commons.intersperse(text_norm, 0)\n    text_norm = torch.LongTensor(text_norm)\n    return text_norm","metadata":{"execution":{"iopub.status.busy":"2023-04-02T10:34:14.888447Z","iopub.execute_input":"2023-04-02T10:34:14.888995Z","iopub.status.idle":"2023-04-02T10:34:22.443848Z","shell.execute_reply.started":"2023-04-02T10:34:14.888962Z","shell.execute_reply":"2023-04-02T10:34:22.44275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 翻译\nfrom transformers import (\n  T5Tokenizer,\n  MT5ForConditionalGeneration,\n  Text2TextGenerationPipeline,\n)\n\npath = \"engmatic-earth/mt5-zh-ja-en-trimmed-fine-tuned-v1\"\npipe = Text2TextGenerationPipeline(\n    model=MT5ForConditionalGeneration.from_pretrained(path),\n    tokenizer=T5Tokenizer.from_pretrained(path),\n    device=1,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T10:34:22.445421Z","iopub.execute_input":"2023-04-02T10:34:22.446179Z","iopub.status.idle":"2023-04-02T10:35:00.095232Z","shell.execute_reply.started":"2023-04-02T10:34:22.44611Z","shell.execute_reply":"2023-04-02T10:35:00.094172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\nfilePath = snapshot_download(repo_id=\"THUDM/chatglm-6b\")\nprint(filePath)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T10:35:00.097117Z","iopub.execute_input":"2023-04-02T10:35:00.09755Z","iopub.status.idle":"2023-04-02T10:36:02.548707Z","shell.execute_reply.started":"2023-04-02T10:35:00.097508Z","shell.execute_reply":"2023-04-02T10:36:02.546549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 加载ChatGLM模型\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\n# from accelerate import load_checkpoint_and_dispatch\nfrom accelerate import load_checkpoint_and_dispatch, init_empty_weights\n\ntokenizer = AutoTokenizer.from_pretrained(filePath, device_map=\"auto\", trust_remote_code=True)\nconfig = AutoConfig.from_pretrained(filePath, trust_remote_code=True)\n# 由于模型较大，使用accelerate库进行分布式加载\nwith init_empty_weights():\n    chat_model = AutoModel.from_config(config, trust_remote_code=True)\nchat_model = load_checkpoint_and_dispatch(\n    chat_model, filePath, device_map=\"auto\", no_split_module_classes=[\"GLMBlock\"]\n).half()\nchat_model = chat_model.eval()","metadata":{"execution":{"iopub.status.busy":"2023-04-02T10:36:02.554548Z","iopub.execute_input":"2023-04-02T10:36:02.555035Z","iopub.status.idle":"2023-04-02T10:37:21.590449Z","shell.execute_reply.started":"2023-04-02T10:36:02.554982Z","shell.execute_reply":"2023-04-02T10:37:21.587398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 模型参数量\nnum_parameters = 0\nparameters = chat_model.parameters()\nfor parameter in parameters:\n    num_parameters += parameter.numel()\nnum_parameters","metadata":{"execution":{"iopub.status.busy":"2023-04-02T10:37:21.592348Z","iopub.execute_input":"2023-04-02T10:37:21.594515Z","iopub.status.idle":"2023-04-02T10:37:21.605853Z","shell.execute_reply.started":"2023-04-02T10:37:21.594466Z","shell.execute_reply":"2023-04-02T10:37:21.604745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install git-lfs\n!git lfs install\n!git clone https://huggingface.co/spaces/skytnt/moe-tts","metadata":{"execution":{"iopub.status.busy":"2023-04-02T10:37:21.607507Z","iopub.execute_input":"2023-04-02T10:37:21.607895Z","iopub.status.idle":"2023-04-02T10:38:26.184118Z","shell.execute_reply.started":"2023-04-02T10:37:21.607856Z","shell.execute_reply":"2023-04-02T10:38:26.182808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nhps = utils.get_hparams_from_file('/kaggle/working/moe-tts/saved_model/0/config.json')\nnet_g = SynthesizerTrn(\n    len(symbols),\n    hps.data.filter_length // 2 + 1,\n    hps.train.segment_size // hps.data.hop_length,\n    n_speakers=hps.data.n_speakers,\n    **hps.model).to(device)\nnet_g.eval()\n_ = utils.load_checkpoint('/kaggle/working/moe-tts/saved_model/0/model.pth', net_g, None)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T10:38:26.189961Z","iopub.execute_input":"2023-04-02T10:38:26.191092Z","iopub.status.idle":"2023-04-02T10:38:27.49437Z","shell.execute_reply.started":"2023-04-02T10:38:26.191043Z","shell.execute_reply":"2023-04-02T10:38:27.49328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython\nspeaker_id = 0\nhistory = []\n# 调整参数\nmax_length, top_p, temperature=2048, 0.7, 0.95\n\n# enable_conversation：是否启动对话模式（即翻译+生成语音），设定部分可以选择不翻译\nenable_conversation = False\n\nwhile True:\n    try:\n        sen = input('你：')\n        if not enable_conversation and sen == '对话':\n            print('启动对话模式')\n            enable_conversation = True\n            continue\n        if enable_conversation and sen == '取消对话':\n            print('取消对话模式')\n            enable_conversation = False\n            continue\n        if sen == '角色':\n            while True:\n                print('SpeakerID: ')\n                print('0: Nene\\n1: Meguru\\n2: Yoshino\\n3: Mako\\n4: Murasame\\n5: Koharu\\n6: Nanami')\n                input_id = int(input('Your speaker ID: '))\n                if input_id >= 0 and input_id < 7:\n                    speaker_id = input_id\n                    print(f'Your speaker ID is {speaker_id}')\n                    break\n                else:\n                    print(\"无效角色ID，SpeakerID必须在0-6之间\")\n            continue\n        \n        response, history = chat_model.chat(tokenizer, sen, max_length=max_length, \n                            top_p=top_p, temperature=temperature, history=history)\n#         print(history)\n        if enable_conversation:\n            with torch.no_grad():\n                sentence = \"zh2ja\" + response\n                res = pipe(sentence, max_length=200, num_beams=4)\n                translated = res[0]['generated_text']\n                translated = translated.replace(' ','、')\n                # 合成语音\n                stn_tst = get_text(translated, hps)\n                x_tst = stn_tst.to(device).unsqueeze(0)\n                x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)\n                # LongTensor里的数字对应不同的角色声音\n                sid = torch.LongTensor([speaker_id]).to(device)\n                audio = net_g.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=.667, noise_scale_w=0.8, length_scale=1)[0][0,0].data.cpu().float().numpy()\n            write(\"output.wav\", hps.data.sampling_rate, audio)\n            \n        print('你老婆：', response)\n        if enable_conversation:\n            print('翻译：', translated)\n            audio = IPython.display.Audio(\"output.wav\", rate=hps.data.sampling_rate, autoplay=True)\n            IPython.display.display(audio)\n    except KeyboardInterrupt:\n            break","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-02T10:50:01.991678Z","iopub.execute_input":"2023-04-02T10:50:01.993423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}